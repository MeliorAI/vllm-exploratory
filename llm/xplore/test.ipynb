{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to explore the use of open source models such as \"facebook/opt-125m\" and \"neuralmagic/Llama-2-7b-chat-quantized.w8a8\", these models are relatively small in size and can be used from my g4dn.2xlarge instance.\n",
    "In addition I compare the output from the open source model to openai.\n",
    "The opensource model is loaded with vllm serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers torch -q\n",
    "!pip install langchain -q\n",
    "!pip install -U langchain-community -q\n",
    "!pip install python-dotenv openai -q\n",
    "!pip3 install pysqlite3-binary -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "def download_file_from_s3(bucket_name, s3_file_key):\n",
    "    # download files to local environment\n",
    "    # Create an S3 client\n",
    "    s3 = boto3.client('s3')\n",
    "    local_file_path = s3_file_key.split('/')[-1]\n",
    "    # Download the file from S3\n",
    "    s3.download_file(bucket_name, s3_file_key, local_file_path)\n",
    "    print(f\"File {s3_file_key} downloaded from {bucket_name} to {local_file_path}\")\n",
    "\n",
    "def delete_file(file_path):\n",
    "    os.remove(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "_RE_COMBINE_WHITESPACE = re.compile(r\"[ ]+\", re.ASCII)\n",
    "_RE_SHORT_LINES = re.compile(\"^.{1,3}\\n\", re.MULTILINE)\n",
    "_RE_MULTILINE_BREAKS = re.compile(\"\\n+\", re.MULTILINE)\n",
    "_RE_PAGE_CHAR = \"\\x0c\"\n",
    "_RE_LATIN_WHITESPACE_CHAR = re.compile(\"\\xa0\", re.ASCII)\n",
    "\n",
    "\n",
    "# @markdown  - **clean_text** - clean text spaces,non-printable and line breaks\n",
    "def clean_text(text):\n",
    "    \"\"\"Clean text from several white-space and line-breaks\"\"\"\n",
    "    # remove several line breaks\n",
    "    text = _RE_LATIN_WHITESPACE_CHAR.sub(\" \", text)\n",
    "    # remove several white spaces\n",
    "    text = _RE_COMBINE_WHITESPACE.sub(\" \", text).strip()\n",
    "    # remove very short lines\n",
    "    text = _RE_SHORT_LINES.sub(\"\\n\", text)\n",
    "    # remove several line breaks\n",
    "    text = _RE_MULTILINE_BREAKS.sub(\"\\n\", text)\n",
    "    # remove unknown characters or non printable\n",
    "    text = \"\".join([x for x in text if x in string.printable])\n",
    "\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File client-data/AAA/NY State Insurance/06-FRM-AR1/FRM-AR117-21-1230-2624_2024_163320/FRM-AR117-21-1230-2624_2024_163320.json downloaded from contract-intelligence-data to FRM-AR117-21-1230-2624_2024_163320.json\n",
      "File client-data/AAA/NY State Insurance/06-FRM-AR1/FRM-AR117-21-1230-2638_2024_162334/FRM-AR117-21-1230-2638_2024_162334.json downloaded from contract-intelligence-data to FRM-AR117-21-1230-2638_2024_162334.json\n",
      "File client-data/AAA/NY State Insurance/06-FRM-AR1/FRM-AR117-22-1252-6330_2024_16400/FRM-AR117-22-1252-6330_2024_16400.json downloaded from contract-intelligence-data to FRM-AR117-22-1252-6330_2024_16400.json\n",
      "File client-data/AAA/NY State Insurance/04-RPT-INIT/17-22-1250-8464/17-22-1250-8464.json downloaded from contract-intelligence-data to 17-22-1250-8464.json\n"
     ]
    }
   ],
   "source": [
    "#for the test data I will use some (parsed) files from here s3://contract-intelligence-data/client-data/AAA/NY State Insurance/06-FRM-AR1/ \n",
    "# these are files of good quality\n",
    "\n",
    "download_file_from_s3(\"contract-intelligence-data\", \"client-data/AAA/NY State Insurance/06-FRM-AR1/FRM-AR117-21-1230-2624_2024_163320/FRM-AR117-21-1230-2624_2024_163320.json\")\n",
    "download_file_from_s3(\"contract-intelligence-data\", \"client-data/AAA/NY State Insurance/06-FRM-AR1/FRM-AR117-21-1230-2638_2024_162334/FRM-AR117-21-1230-2638_2024_162334.json\")\n",
    "download_file_from_s3(\"contract-intelligence-data\", \"client-data/AAA/NY State Insurance/06-FRM-AR1/FRM-AR117-22-1252-6330_2024_16400/FRM-AR117-22-1252-6330_2024_16400.json\")\n",
    "\n",
    "download_file_from_s3(\"contract-intelligence-data\",\"client-data/AAA/NY State Insurance/04-RPT-INIT/17-22-1250-8464/17-22-1250-8464.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "def read_files(docs_dir: str):\n",
    "    files = glob.glob(os.path.join(docs_dir,\"*.json\"), recursive=True)\n",
    "    print(f\"Total number of docs: {len(files)}\")\n",
    "    return files\n",
    "\n",
    "def compose_dataset(docs_dir: str):\n",
    "    files = read_files(docs_dir)\n",
    "    print(files)\n",
    "    # Read & Load the Dataset\n",
    "    dataset = []\n",
    "    for file in tqdm(files):\n",
    "        # data in json format after ocr\n",
    "        with open(file) as f:\n",
    "            pdoc = json.load(f)\n",
    "        dataset.append(pdoc)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of docs: 4\n",
      "['./FRM-AR117-21-1230-2624_2024_163320.json', './17-22-1250-8464.json', './FRM-AR117-21-1230-2638_2024_162334.json', './FRM-AR117-22-1252-6330_2024_16400.json']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 3413.47it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = compose_dataset(\".\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_community.embeddings import CohereEmbeddings, OpenAIEmbeddings\n",
    "from langchain.chains.retrieval_qa.base import RetrievalQA\n",
    "from langchain.schema import Document\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The rag part, based on the one in LINT api\n",
    "\n",
    "DEFAULT_CHUNK_SIZE = 3500  #1400 (had to reduce to fit into the facebook/opt-125m model)\n",
    "DEFAULT_CHUNK_OVERLAP = 500\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\"#I will still use openai for embeddings\n",
    "# next step can also try and replace the embeddings for opensource ones\n",
    "LLM_MODEL_OPENAI = \"gpt-3.5-turbo\"\n",
    "vector_db_path = './chroma_db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv, dotenv_values\n",
    "import openai\n",
    "path_to_keys = 'keys.env'\n",
    "temp = dotenv_values(path_to_keys)\n",
    "openai_api_key = temp[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lets put the data to chroma db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "__import__('pysqlite3')\n",
    "import sys\n",
    "sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install hnswlib==0.7.0 -q\n",
    "# !pip install chroma-hnswlib==0.7.3 -q\n",
    "# !pip uninstall hnswlib chroma-hnswlib -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install chromadb==0.5 tiktoken -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "def put_in_Chroma(doc_pages, doc_name):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=DEFAULT_CHUNK_SIZE, chunk_overlap=DEFAULT_CHUNK_OVERLAP)\n",
    "    doc = [\n",
    "                Document(page_content=clean_text(page), metadata={\"page\": i, \"doc_name\": doc_name})\n",
    "                for i, page in enumerate(doc_pages)\n",
    "            ]\n",
    "    chunks = text_splitter.split_documents(doc)\n",
    "    print('chunks: ', len(chunks))\n",
    "    # Retrieve embedding function from code env resources\n",
    "    embeddings = OpenAIEmbeddings(model=EMBEDDING_MODEL, openai_api_key=openai_api_key)\n",
    "\n",
    "    # Index the vector database by embedding then inserting document chunks\n",
    "    db = Chroma.from_documents(chunks,\n",
    "                            embedding=embeddings,\n",
    "                            ids=[str(i) for i in range(len(chunks))],\n",
    "                            persist_directory=vector_db_path)\n",
    "\n",
    "    # Save vector database as persistent files in the output folder\n",
    "    # db.persist()\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pages:  10\n",
      "chunks:  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_322652/2804527872.py:12: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embeddings = OpenAIEmbeddings(model=EMBEDDING_MODEL, openai_api_key=openai_api_key)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.31 s, sys: 112 ms, total: 1.42 s\n",
      "Wall time: 2.53 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# file_name = 'FRM-AR117-21-1230-2624_2024_163320'\n",
    "# file_name = 'FRM-AR117-21-1230-2638_2024_162334'\n",
    "file_name = 'FRM-AR117-22-1252-6330_2024_16400'\n",
    "# file_name = '17-22-1250-8464'\n",
    "for i in dataset:\n",
    "    if i['name'] == file_name:\n",
    "        doc_pages = i['text']\n",
    "        break\n",
    "print('pages: ', len(doc_pages))\n",
    "db = put_in_Chroma(doc_pages, doc_name=file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gpt_llm():\n",
    "    chat_params = {\n",
    "        \"model\": \"gpt-3.5-turbo\", # Bigger context window\n",
    "        \"openai_api_key\": openai_api_key,\n",
    "        \"temperature\": 0.000001, \n",
    "    }\n",
    "    llm = ChatOpenAI(**chat_params)\n",
    "    return llm\n",
    "\n",
    "def qa_retriever_openai(query, vector_db_path, file_id, k=4):\n",
    "    embeddings = OpenAIEmbeddings(model=EMBEDDING_MODEL, openai_api_key=openai_api_key)\n",
    "    vectordb = Chroma(persist_directory=vector_db_path, embedding_function=embeddings)\n",
    "\n",
    "    retriever = vectordb.as_retriever(search_kwargs={\"k\": k, \"filter\": {\"doc_name\": file_id}})\n",
    "\n",
    "    qa = RetrievalQA.from_chain_type(llm=get_gpt_llm(), chain_type=\"stuff\", \n",
    "                                    retriever=retriever, return_source_documents=True)\n",
    "    res = qa({\"query\": query, \"k\": k})\n",
    "    return res, retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_322652/1329014412.py:12: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectordb = Chroma(persist_directory=vector_db_path, embedding_function=embeddings)\n",
      "/tmp/ipykernel_322652/1329014412.py:7: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(**chat_params)\n",
      "/tmp/ipykernel_322652/1329014412.py:18: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  res = qa({\"query\": query, \"k\": k})\n"
     ]
    }
   ],
   "source": [
    "question = \"Who are the parties?\"\n",
    "\n",
    "# file_name = 'FRM-AR117-21-1230-2624_2024_163320'\n",
    "# file_name = 'FRM-AR117-21-1230-2638_2024_162334'\n",
    "# file_name = '17-22-1250-8464'\n",
    "file_name = 'FRM-AR117-22-1252-6330_2024_16400'\n",
    "answer, retriever = qa_retriever_openai(question, vector_db_path=\"/home/ubuntu/yulia/vllm-exploratory/llm/xplore/chroma_db\", file_id=file_name, k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Who are the parties?',\n",
       " 'k': 4,\n",
       " 'result': 'The parties involved in this case are:\\n\\n1. Applicant Attorney: Korsunskiy Legal Group P.C.\\n2. Medical Provider: Mazal Pharmacy Inc d/b/a Mirage Pharmacy\\n3. Injured Party: Annmarie Morris',\n",
       " 'source_documents': [Document(metadata={'doc_name': 'FRM-AR117-22-1252-6330_2024_16400', 'page': 9}, page_content='Your name:\\nSigned on:'),\n",
       "  Document(metadata={'doc_name': 'FRM-AR117-22-1252-6330_2024_16400', 'page': 0}, page_content='New York Motor Vehicle No-Fault Insurance Law Arbitration Request Form\\nDetails of the parties\\nApplicant Attorney Details\\nFull Legal Name Korsunskiy Legal Group P.C.\\nAddress 3237 Long Beach Road\\nAddress Suite 110\\nCity Oceanside\\nState NY\\nZip 11572\\nEmail dkorsunskiy @korsunskiy-law.com\\nPhone 718-758-4755\\nApplicant File Number DK22-243552'),\n",
       "  Document(metadata={'doc_name': 'FRM-AR117-22-1252-6330_2024_16400', 'page': 4}, page_content='Details of the Accident\\nDid the accident occur in New York\\nState? Yes\\nIf no, Is the injured person or a\\nmember of their household a New No\\nYork State Automobile Policy\\nHolder?\\nDate Of Accident 11/20/2021\\nDescription Of Accident\\nPosition Of Injured Party\\nDate of last contact\\nPerson contacted\\nReason given by insurer for\\nnonpayment of claim(s)\\nReason you believe the denied or\\noverdue benefits should be paid'),\n",
       "  Document(metadata={'doc_name': 'FRM-AR117-22-1252-6330_2024_16400', 'page': 1}, page_content='Applicant for benefits - Medical Provider\\nFull Legal Name\\nMazal Pharmacy Inc d/b/a Mirage Pharmacy\\nAddress 1 1674 East 22 street\\nAddress 2 2nd Floor\\nCity Brooklyn\\nState NY\\nZip 11229\\nEmail donotemail5014701 @adr.org\\nPhone 000-000-0000\\nInjured Party\\nFull Legal Name\\nAnnmarie Morris\\nCity\\nState\\nEmail\\nPhone\\nFax')]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Openai answer:  The parties involved in this case are:\n",
      "\n",
      "1. Applicant Attorney: Korsunskiy Legal Group P.C.\n",
      "2. Medical Provider: Mazal Pharmacy Inc d/b/a Mirage Pharmacy\n",
      "3. Injured Party: Annmarie Morris\n"
     ]
    }
   ],
   "source": [
    "print('Openai answer: ', answer['result'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ran in terminal: `vllm serve neuralmagic/Llama-2-7b-chat-quantized.w8a8 --chat-template templates/template_chatml.jinja`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_server_url = \"http://localhost:8000/v1\"\n",
    "\n",
    "# MODEL = \"facebook/opt-125m\"\n",
    "MODEL = \"neuralmagic/Llama-2-7b-chat-quantized.w8a8\"\n",
    "    \n",
    "llm = ChatOpenAI(\n",
    "    model=MODEL,\n",
    "    openai_api_key=\"EMPTY\",\n",
    "    openai_api_base=inference_server_url,\n",
    "    max_tokens=100,\n",
    "    temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qa_retriever_llama(query, vector_db_path, file_id, k=4):\n",
    "    embeddings = OpenAIEmbeddings(model=EMBEDDING_MODEL, openai_api_key=openai_api_key)\n",
    "    vectordb = Chroma(persist_directory=vector_db_path, embedding_function=embeddings)\n",
    "\n",
    "    retriever = vectordb.as_retriever(search_kwargs={\"k\": k, \"filter\": {\"doc_name\": file_id}})\n",
    "\n",
    "    qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", \n",
    "                                    retriever=retriever, return_source_documents=True)\n",
    "    res = qa({\"query\": query})\n",
    "    return res, retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Who are the parties?\"\n",
    "# file_name = 'FRM-AR117-21-1230-2624_2024_163320'\n",
    "# file_name = 'FRM-AR117-21-1230-2638_2024_162334'\n",
    "# file_name = '17-22-1250-8464'\n",
    "\n",
    "file_name = 'FRM-AR117-22-1252-6330_2024_16400'\n",
    "answer, retriever = qa_retriever_llama(question, vector_db_path=\"/home/ubuntu/yulia/vllm-exploratory/llm/xplore/chroma_db\", file_id=file_name, k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Who are the parties?',\n",
       " 'result': 'The parties involved in this arbitration request are:\\n\\n* Applicant: Mazal Pharmacy Inc d/b/a Mirage Pharmacy, the medical provider seeking payment of benefits for Annmarie Morris, the injured party.\\n* Insurer: The insurance company that issued the policy to Annmarie Morris, the injured party.\\n* Applicant Attorney: Korsunskiy Legal Group P.C., the law firm representing Maz',\n",
       " 'source_documents': [Document(metadata={'doc_name': 'FRM-AR117-22-1252-6330_2024_16400', 'page': 9}, page_content='Your name:\\nSigned on:'),\n",
       "  Document(metadata={'doc_name': 'FRM-AR117-22-1252-6330_2024_16400', 'page': 0}, page_content='New York Motor Vehicle No-Fault Insurance Law Arbitration Request Form\\nDetails of the parties\\nApplicant Attorney Details\\nFull Legal Name Korsunskiy Legal Group P.C.\\nAddress 3237 Long Beach Road\\nAddress Suite 110\\nCity Oceanside\\nState NY\\nZip 11572\\nEmail dkorsunskiy @korsunskiy-law.com\\nPhone 718-758-4755\\nApplicant File Number DK22-243552'),\n",
       "  Document(metadata={'doc_name': 'FRM-AR117-22-1252-6330_2024_16400', 'page': 4}, page_content='Details of the Accident\\nDid the accident occur in New York\\nState? Yes\\nIf no, Is the injured person or a\\nmember of their household a New No\\nYork State Automobile Policy\\nHolder?\\nDate Of Accident 11/20/2021\\nDescription Of Accident\\nPosition Of Injured Party\\nDate of last contact\\nPerson contacted\\nReason given by insurer for\\nnonpayment of claim(s)\\nReason you believe the denied or\\noverdue benefits should be paid'),\n",
       "  Document(metadata={'doc_name': 'FRM-AR117-22-1252-6330_2024_16400', 'page': 1}, page_content='Applicant for benefits - Medical Provider\\nFull Legal Name\\nMazal Pharmacy Inc d/b/a Mirage Pharmacy\\nAddress 1 1674 East 22 street\\nAddress 2 2nd Floor\\nCity Brooklyn\\nState NY\\nZip 11229\\nEmail donotemail5014701 @adr.org\\nPhone 000-000-0000\\nInjured Party\\nFull Legal Name\\nAnnmarie Morris\\nCity\\nState\\nEmail\\nPhone\\nFax')]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parties involved in this arbitration request are:\n",
      "\n",
      "* Applicant: Mazal Pharmacy Inc d/b/a Mirage Pharmacy, the medical provider seeking payment of benefits for Annmarie Morris, the injured party.\n",
      "* Insurer: The insurance company that issued the policy to Annmarie Morris, the injured party.\n",
      "* Applicant Attorney: Korsunskiy Legal Group P.C., the law firm representing Maz\n"
     ]
    }
   ],
   "source": [
    "print(answer['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your name:\n",
      "Signed on:\n",
      "--\n",
      "New York Motor Vehicle No-Fault Insurance Law Arbitration Request Form\n",
      "Details of the parties\n",
      "Applicant Attorney Details\n",
      "Full Legal Name Korsunskiy Legal Group P.C.\n",
      "Address 3237 Long Beach Road\n",
      "Address Suite 110\n",
      "City Oceanside\n",
      "State NY\n",
      "Zip 11572\n",
      "Email dkorsunskiy @korsunskiy-law.com\n",
      "Phone 718-758-4755\n",
      "Applicant File Number DK22-243552\n",
      "--\n",
      "Details of the Accident\n",
      "Did the accident occur in New York\n",
      "State? Yes\n",
      "If no, Is the injured person or a\n",
      "member of their household a New No\n",
      "York State Automobile Policy\n",
      "Holder?\n",
      "Date Of Accident 11/20/2021\n",
      "Description Of Accident\n",
      "Position Of Injured Party\n",
      "Date of last contact\n",
      "Person contacted\n",
      "Reason given by insurer for\n",
      "nonpayment of claim(s)\n",
      "Reason you believe the denied or\n",
      "overdue benefits should be paid\n",
      "--\n",
      "Applicant for benefits - Medical Provider\n",
      "Full Legal Name\n",
      "Mazal Pharmacy Inc d/b/a Mirage Pharmacy\n",
      "Address 1 1674 East 22 street\n",
      "Address 2 2nd Floor\n",
      "City Brooklyn\n",
      "State NY\n",
      "Zip 11229\n",
      "Email donotemail5014701 @adr.org\n",
      "Phone 000-000-0000\n",
      "Injured Party\n",
      "Full Legal Name\n",
      "Annmarie Morris\n",
      "City\n",
      "State\n",
      "Email\n",
      "Phone\n",
      "Fax\n"
     ]
    }
   ],
   "source": [
    "text = '\\n--\\n'.join([i.page_content for i in answer['source_documents']])\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts.prompt import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=MODEL,\n",
    "    openai_api_key=\"EMPTY\",\n",
    "    openai_api_base=inference_server_url,\n",
    "    max_tokens=200,\n",
    "    temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are an AI assistant, use the following text to provide answer if you don't know, say you don't know\n",
    "        Context: {context}\n",
    "        Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "# context = text\n",
    "question = \"Who are the parties?\"\n",
    "question = \"Where did the accident occur?\"\n",
    "# question = \"What is the date of the accident?\"\n",
    "# question = \"Was the denial of claim based on late notice to the carrier?\"\n",
    "# question = \"Who is the insurer?\"\n",
    "# question = \"What type of form is that?\"\n",
    "\n",
    "file_name = 'FRM-AR117-22-1252-6330_2024_16400'\n",
    "vector_db_path = \"/home/ubuntu/yulia/vllm-exploratory/llm/xplore/chroma_db\"\n",
    "my_prompt = PromptTemplate(template=prompt, input_variables=[\"context\", \"question\"])\n",
    "embeddings = OpenAIEmbeddings(model=EMBEDDING_MODEL, openai_api_key=openai_api_key)\n",
    "vectordb = Chroma(persist_directory=vector_db_path, embedding_function=embeddings)\n",
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 4, \"filter\": {\"doc_name\": file_name}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(llm=llm, \n",
    "                                chain_type=\"stuff\", \n",
    "                                retriever=retriever, \n",
    "                                return_source_documents=True,\n",
    "                                chain_type_kwargs={\"prompt\": my_prompt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.7 ms, sys: 471 μs, total: 22.2 ms\n",
      "Wall time: 8.61 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "llama_answer = qa.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Where did the accident occur?',\n",
       " 'result': \"I'm just an AI, I don't have access to specific information about the accident or the parties involved. However, I can provide general information on New York Motor Vehicle No-Fault Insurance Law and the arbitration process.\\n\\nThe New York Motor Vehicle No-Fault Insurance Law requires that all motor vehicles registered in New York State be covered by a no-fault insurance policy. This policy provides coverage for medical expenses and lost wages to the insured party and passengers in the event of an accident, regardless of fault.\\n\\nIf an insurer denies or overpays a claim, the insured party or their attorney can file an arbitration request with the New York State Department of Financial Services (DFS). The arbitration process is special expedited, which means that the case will be heard and decided by an arbitrator within 30 days of the request.\\n\\nTo\",\n",
       " 'source_documents': [Document(metadata={'doc_name': 'FRM-AR117-22-1252-6330_2024_16400', 'page': 4}, page_content='Details of the Accident\\nDid the accident occur in New York\\nState? Yes\\nIf no, Is the injured person or a\\nmember of their household a New No\\nYork State Automobile Policy\\nHolder?\\nDate Of Accident 11/20/2021\\nDescription Of Accident\\nPosition Of Injured Party\\nDate of last contact\\nPerson contacted\\nReason given by insurer for\\nnonpayment of claim(s)\\nReason you believe the denied or\\noverdue benefits should be paid'),\n",
       "  Document(metadata={'doc_name': 'FRM-AR117-22-1252-6330_2024_16400', 'page': 0}, page_content='New York Motor Vehicle No-Fault Insurance Law Arbitration Request Form\\nDetails of the parties\\nApplicant Attorney Details\\nFull Legal Name Korsunskiy Legal Group P.C.\\nAddress 3237 Long Beach Road\\nAddress Suite 110\\nCity Oceanside\\nState NY\\nZip 11572\\nEmail dkorsunskiy @korsunskiy-law.com\\nPhone 718-758-4755\\nApplicant File Number DK22-243552'),\n",
       "  Document(metadata={'doc_name': 'FRM-AR117-22-1252-6330_2024_16400', 'page': 9}, page_content='Your name:\\nSigned on:'),\n",
       "  Document(metadata={'doc_name': 'FRM-AR117-22-1252-6330_2024_16400', 'page': 6}, page_content='Special Expedited Arbitration (Late Notice)\\n(LINYCRR 65-4.5 (b) provides for Special Expedited Arbitration proceedings for cases that were denied based on failure to submit notice of claim\\nwithin 30 days after the accident. To qualify you must request Special Expedited Arbitration within 30 days after the mailing of the denial.)\\nWas the denial of claim based on late notice to the carrier?\\nIf yes, are you requesting Special Expedited Arbitration?\\nNo')]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(llama_answer)\n",
    "print(llama_answer['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_prompt = PromptTemplate(template=prompt, input_variables=[\"context\", \"question\"])\n",
    "embeddings = OpenAIEmbeddings(model=EMBEDDING_MODEL, openai_api_key=openai_api_key)\n",
    "vectordb = Chroma(persist_directory=vector_db_path, embedding_function=embeddings)\n",
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 4, \"filter\": {\"doc_name\": file_name}})\n",
    "qa = RetrievalQA.from_chain_type(llm=get_gpt_llm(), \n",
    "                                chain_type=\"stuff\", \n",
    "                                retriever=retriever, \n",
    "                                return_source_documents=True,\n",
    "                                chain_type_kwargs={\"prompt\": my_prompt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.9 ms, sys: 308 μs, total: 23.2 ms\n",
      "Wall time: 719 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "openai_answer = qa.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'Where did the accident occur?', 'result': 'The accident occurred in New York State.', 'source_documents': [Document(metadata={'doc_name': 'FRM-AR117-22-1252-6330_2024_16400', 'page': 4}, page_content='Details of the Accident\\nDid the accident occur in New York\\nState? Yes\\nIf no, Is the injured person or a\\nmember of their household a New No\\nYork State Automobile Policy\\nHolder?\\nDate Of Accident 11/20/2021\\nDescription Of Accident\\nPosition Of Injured Party\\nDate of last contact\\nPerson contacted\\nReason given by insurer for\\nnonpayment of claim(s)\\nReason you believe the denied or\\noverdue benefits should be paid'), Document(metadata={'doc_name': 'FRM-AR117-22-1252-6330_2024_16400', 'page': 0}, page_content='New York Motor Vehicle No-Fault Insurance Law Arbitration Request Form\\nDetails of the parties\\nApplicant Attorney Details\\nFull Legal Name Korsunskiy Legal Group P.C.\\nAddress 3237 Long Beach Road\\nAddress Suite 110\\nCity Oceanside\\nState NY\\nZip 11572\\nEmail dkorsunskiy @korsunskiy-law.com\\nPhone 718-758-4755\\nApplicant File Number DK22-243552'), Document(metadata={'doc_name': 'FRM-AR117-22-1252-6330_2024_16400', 'page': 9}, page_content='Your name:\\nSigned on:'), Document(metadata={'doc_name': 'FRM-AR117-22-1252-6330_2024_16400', 'page': 6}, page_content='Special Expedited Arbitration (Late Notice)\\n(LINYCRR 65-4.5 (b) provides for Special Expedited Arbitration proceedings for cases that were denied based on failure to submit notice of claim\\nwithin 30 days after the accident. To qualify you must request Special Expedited Arbitration within 30 days after the mailing of the denial.)\\nWas the denial of claim based on late notice to the carrier?\\nIf yes, are you requesting Special Expedited Arbitration?\\nNo')]}\n",
      "The accident occurred in New York State.\n"
     ]
    }
   ],
   "source": [
    "print(openai_answer)\n",
    "print(openai_answer['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['0', '1', '2', '3', '4', '5', '6', '7', '8'],\n",
       " 'embeddings': None,\n",
       " 'metadatas': [{'doc_name': 'FRM-AR117-22-1252-6330_2024_16400', 'page': 0},\n",
       "  {'doc_name': 'FRM-AR117-22-1252-6330_2024_16400', 'page': 1},\n",
       "  {'doc_name': 'FRM-AR117-22-1252-6330_2024_16400', 'page': 2},\n",
       "  {'doc_name': 'FRM-AR117-22-1252-6330_2024_16400', 'page': 4},\n",
       "  {'doc_name': 'FRM-AR117-22-1252-6330_2024_16400', 'page': 5},\n",
       "  {'doc_name': 'FRM-AR117-22-1252-6330_2024_16400', 'page': 6},\n",
       "  {'doc_name': 'FRM-AR117-22-1252-6330_2024_16400', 'page': 7},\n",
       "  {'doc_name': 'FRM-AR117-22-1252-6330_2024_16400', 'page': 8},\n",
       "  {'doc_name': 'FRM-AR117-22-1252-6330_2024_16400', 'page': 9}],\n",
       " 'documents': ['New York Motor Vehicle No-Fault Insurance Law Arbitration Request Form\\nDetails of the parties\\nApplicant Attorney Details\\nFull Legal Name Korsunskiy Legal Group P.C.\\nAddress 3237 Long Beach Road\\nAddress Suite 110\\nCity Oceanside\\nState NY\\nZip 11572\\nEmail dkorsunskiy @korsunskiy-law.com\\nPhone 718-758-4755\\nApplicant File Number DK22-243552',\n",
       "  'Applicant for benefits - Medical Provider\\nFull Legal Name\\nMazal Pharmacy Inc d/b/a Mirage Pharmacy\\nAddress 1 1674 East 22 street\\nAddress 2 2nd Floor\\nCity Brooklyn\\nState NY\\nZip 11229\\nEmail donotemail5014701 @adr.org\\nPhone 000-000-0000\\nInjured Party\\nFull Legal Name\\nAnnmarie Morris\\nCity\\nState\\nEmail\\nPhone\\nFax',\n",
       "  'Insurer OR self-insurer\\nFull Legal Name of the Business\\nGeico Insurance Company\\nAddress 1 750 Woodbury Rd\\nCity Woodbury\\nState NY\\nZip 11797\\nEmail R2AAA @geico.com\\nPhone 516-496-5492\\nPolicy Holder\\nFull Legal Name\\nCity\\nState\\nEmail\\nPhone\\nPolicy Number\\n1909073908\\nClaim/file Number\\n0118927330101077\\nIs there a third party administrator: NO',\n",
       "  'Details of the Accident\\nDid the accident occur in New York\\nState? Yes\\nIf no, Is the injured person or a\\nmember of their household a New No\\nYork State Automobile Policy\\nHolder?\\nDate Of Accident 11/20/2021\\nDescription Of Accident\\nPosition Of Injured Party\\nDate of last contact\\nPerson contacted\\nReason given by insurer for\\nnonpayment of claim(s)\\nReason you believe the denied or\\noverdue benefits should be paid',\n",
       "  'Request for Special Handling\\nWritten Submissions Arbitration\\n(11 NYCRR 65-4.5 (a) provides for arbitration on the basis of written submissions, at the discretion of the arbitrator, if the amount in dispute is less\\nthan $2,000.)\\nAre you interested in having this case decided by the arbitrator entirely on the written submissions, without an in-person hearing?\\nAre you interested in having a telephone hearing of this case, instead of an in-person hearing?\\nPriority Arbitration (90-day)\\n11 NYCRR 65-4.5 (i) (2) provides for Priority Arbitration in cases where the request for arbitration is made within 90 days after either a denial of\\nclaim was received or the claim became overdue, for EACH claim in dispute. A file that qualifies for Priority Arbitration is scheduled within 45 days\\nfrom the date of transmittal from the conciliation center.)\\nAre you filing within 90 days after each claim in dispute was denied or became overdue?\\nYes',\n",
       "  'Special Expedited Arbitration (Late Notice)\\n(LINYCRR 65-4.5 (b) provides for Special Expedited Arbitration proceedings for cases that were denied based on failure to submit notice of claim\\nwithin 30 days after the accident. To qualify you must request Special Expedited Arbitration within 30 days after the mailing of the denial.)\\nWas the denial of claim based on late notice to the carrier?\\nIf yes, are you requesting Special Expedited Arbitration?\\nNo',\n",
       "  'Claim(s) in dispute\\nMedical (Attach bills in dispute)\\n. . w\\nInjured Medical . raiq | Amount Dates of Service | Dates of Service Vas cation | Date\\nee ie Specialty Amount of Bill | Amount Paid | (mount eae mae Verification | oo ied\\nRequested?\\nMazal\\nAnnmarie Morris Pharmacy Ine $3,285.00 $173.04 $3,111.96 } 02/10/2022 02/10/2022 No\\nd/b/a Mirage\\nPharmacy\\nTotal $3,285.00 $173.04 $3,111.96\\nAttorney Fee\\nAttorney Fee: No\\nTotal Amount in Dispute\\nTotal Amount in Dispute: $3,111.96\\nDoes this arbitration request include all issues known by the applicant/attorney to be in dispute with the insurer? If no, attach explanation.\\nComments:\\nWas a denial issued? If yes, attach a copy. If no, please explain on what basis claim was not paid.\\nComments:',\n",
       "  'Any person who knowingly and with intent to defraud any insurance company or other person files an application for commercial insurance or a statement of\\nclaim for any commercial or personal insurance benefits containing any materially false information, or conceals for the purpose of misleading, information\\nconcerning any fact material thereto, and any person who, in connection with such application or claim, knowingly makes or knowingly assists, abets, solicits or\\nconspires with another to make a false report of the theft, destruction, damage or conversion of any motor vehicle to a law enforcement agency, the department\\nof motor vehicles or an insurance company, commits a fraudulent insurance act, which is a crime, and shall also be subject to a civil penalty not to exceed five\\nthousand dollars and the value of the subject motor vehicle or stated claim for each violation.\\nThe undersigned affirms and certifies as true under the penalty of perjury that this filing is being made in good faith and that upon information, belief and reasonable\\ninquiry the documents being submitted herewith are not fraudulent and that exact copies of all documents provided herewith have been mailed to the insurer against whom\\nthe arbitration is being requested. Unless disclosed with this submission, the disputed amounts remain unpaid to the applicant by any payor and there has been no other\\nfiling of an arbitration request or lawsuit to resolve the disputed matters contained in this submission.',\n",
       "  'Your name:\\nSigned on:'],\n",
       " 'uris': None,\n",
       " 'data': None}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db._collection.get(include=[\"metadatas\",\"documents\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 10-03 11:02:21 config.py:1657] Casting torch.bfloat16 to torch.float16.\n",
      "INFO 10-03 11:02:21 llm_engine.py:223] Initializing an LLM engine (v0.6.1.post2) with config: model='neuralmagic/Meta-Llama-3.1-8B-Instruct-quantized.w8a8', speculative_config=None, tokenizer='neuralmagic/Meta-Llama-3.1-8B-Instruct-quantized.w8a8', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=compressed-tensors, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=neuralmagic/Meta-Llama-3.1-8B-Instruct-quantized.w8a8, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)\n",
      "INFO 10-03 11:02:22 selector.py:217] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n",
      "INFO 10-03 11:02:22 selector.py:116] Using XFormers backend.\n",
      "INFO 10-03 11:02:24 model_runner.py:997] Starting to load model neuralmagic/Meta-Llama-3.1-8B-Instruct-quantized.w8a8...\n",
      "INFO 10-03 11:02:24 selector.py:217] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n",
      "INFO 10-03 11:02:24 selector.py:116] Using XFormers backend.\n",
      "INFO 10-03 11:02:24 weight_utils.py:242] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:02<00:02,  2.12s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:03<00:00,  1.85s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:03<00:00,  1.89s/it]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 10-03 11:02:29 model_runner.py:1008] Loading model weights took 8.4939 GB\n",
      "INFO 10-03 11:02:33 gpu_executor.py:122] # GPU blocks: 1108, # CPU blocks: 2048\n",
      "INFO 10-03 11:02:35 model_runner.py:1311] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 10-03 11:02:35 model_runner.py:1315] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 10-03 11:03:03 model_runner.py:1430] Graph capturing finished in 28 secs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:05<00:00,  5.59s/it, est. speed input: 9.48 toks/s, output: 21.10 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yer lookin' fer a swashbucklin' introduction, eh? Alright then, matey! Me name be Captain Chatbeard, the scurvy dog o' the seven seas... er, the seven screens! Me and me trusty crew o' code scallywags have been sailin' the digital waters, gatherin' knowledge and tellin' tales o' adventure and danger. So hoist the sails and set course fer a treasure trove o' information, me hearty! What be bringin' ye to these fair waters today?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_id = \"neuralmagic/Meta-Llama-3.1-8B-Instruct-quantized.w8a8\"\n",
    "number_gpus = 1\n",
    "max_model_len = 8192\n",
    "\n",
    "sampling_params = SamplingParams(temperature=0.6, top_p=0.9, max_tokens=256)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "llm = LLM(model=model_id, tensor_parallel_size=number_gpus, max_model_len=max_model_len, dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:11<00:00, 11.97s/it, est. speed input: 4.68 toks/s, output: 21.38 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yer lookin' fer a poem, eh? Alright then, matey, settle yerself down with a pint o' grog and listen close to me tale o' the waterlilies.\n",
      "\n",
      "Oh, waterlilies, ye floatin' beauties o' the deep,\n",
      "Like treasure chests o' the pond, yer secrets ye keep.\n",
      "Yer leaves like green sails, they gently sway,\n",
      "Dancin' to the breeze, on a sunny day.\n",
      "\n",
      "Yer flowers, like golden doubloons, shine so bright,\n",
      "A treasure trove o' beauty, in the mornin' light.\n",
      "The dragonflies and bees, they come to visit ye,\n",
      "To drink from yer sweet nectar, and bask in yer glee.\n",
      "\n",
      "In the still o' the night, ye rise up high,\n",
      "Like a ghost ship, sailin' across the sky.\n",
      "Yer fragrance, like a chest overflowin' with gold,\n",
      "Fills the air, and makes the heart feel bold.\n",
      "\n",
      "So here's to ye, oh waterlilies, a treasure rare,\n",
      "A beauty o' the water, beyond compare.\n",
      "May yer beauty continue, to shine so bright,\n",
      "And bring joy to all, who sail through the night.\n",
      "\n",
      "Now, go forth,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a pirate chatbot who always responds in pirate speak!\"},\n",
    "    {\"role\": \"user\", \"content\": \"write a poem about waterlilies\"},\n",
    "]\n",
    "\n",
    "prompts = tokenizer.apply_chat_template(messages, add_generation_prompt=True, tokenize=False)\n",
    "outputs = llm.generate(prompts, sampling_params)\n",
    "\n",
    "generated_text = outputs[0].outputs[0].text\n",
    "print(generated_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
